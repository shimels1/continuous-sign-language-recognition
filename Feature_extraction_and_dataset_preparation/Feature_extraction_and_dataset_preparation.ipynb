{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shimels1/continuous-sign-language-recognition/blob/main/Feature_extraction_and_dataset_preparation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfQVk29r0AZj",
        "outputId": "ed3fe7e7-da26-4102-8a64-5d1e31989983"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: patool in /usr/local/lib/python3.7/dist-packages (1.12)\n"
          ]
        }
      ],
      "source": [
        "pip install patool"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U --no-cache-dir gdown --pre"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DHPVL5XXh99",
        "outputId": "2bfc27ba-41f2-4e67-90ce-e6cdc4ec53b4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.6.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.63.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kevYr76ulpaX"
      },
      "outputs": [],
      "source": [
        "# import librarys\n",
        "import numpy as np\n",
        "import csv\n",
        "import os\n",
        "import patoolib\n",
        "import cv2\n",
        "import time\n",
        "from PIL import Image, ImageFilter\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from IPython.display import clear_output\n",
        "from google.colab.patches import cv2_imshow\n",
        "import pandas as pd\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Input\n",
        "from keras.layers import BatchNormalization\n",
        "from keras import Model\n",
        "from keras.preprocessing import image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nkpyLpUrepti",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "471a640b-c72a-4623-981c-e7f209671000"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1IxWGcjlOBfgFBA1WOe-Ehlx3qYRXpPI1\n",
            "To: /content/10sentence.rar\n",
            "100% 484M/484M [00:01<00:00, 319MB/s]\n"
          ]
        }
      ],
      "source": [
        "#download dataset from google drive\n",
        "!gdown --id 1IxWGcjlOBfgFBA1WOe-Ehlx3qYRXpPI1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "YM02Hau9nL-F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "3fd3e9fe-dfb0-44eb-f641-ac0f84419c40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "patool: Extracting 10sentence.rar ...\n",
            "patool: running /usr/bin/unrar x -- /content/10sentence.rar\n",
            "patool:     with cwd='./Unpack_n3gycnt8'\n",
            "patool: ... 10sentence.rar extracted to `10sentence'.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'10sentence'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# extract the dataset\n",
        "patoolib.extract_archive(\"10sentence.rar\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WHGlNF4Nlt53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31aa786f-730d-4dbc-8208-ba5484d5199f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 1)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 222, 222, 32)      320       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 222, 222, 32)     128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 111, 111, 32)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 109, 109, 64)     256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 54, 54, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 52, 52, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 52, 52, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 26, 26, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 24, 24, 256)       295168    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 24, 24, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 12, 12, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 10, 10, 512)       1180160   \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 10, 10, 512)      2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 5, 5, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 3, 3, 1024)        4719616   \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 3, 3, 1024)       4096      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 1, 1, 1024)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1, 1, 1024)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,295,680\n",
            "Trainable params: 6,291,648\n",
            "Non-trainable params: 4,032\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# define feature extraction model\n",
        "\n",
        "inputs = Input(shape=[224, 224, 1])\n",
        "\n",
        "cnnModel = Convolution2D(filters=32, kernel_size=3, activation='relu', input_shape=[224, 224, 1])(inputs)\n",
        "cnnModel = BatchNormalization()(cnnModel)\n",
        "cnnModel = MaxPooling2D(pool_size=2, strides=2)(cnnModel)\n",
        "\n",
        "cnnModel = Convolution2D(filters=64, kernel_size=3, activation='relu')(cnnModel)\n",
        "cnnModel = BatchNormalization()(cnnModel)\n",
        "cnnModel = MaxPooling2D(pool_size=2, strides=2)(cnnModel)\n",
        "\n",
        "cnnModel = Convolution2D(filters=128, kernel_size=3, activation='relu')(cnnModel)\n",
        "cnnModel = BatchNormalization()(cnnModel)\n",
        "cnnModel = MaxPooling2D(pool_size=2, strides=2)(cnnModel)\n",
        "\n",
        "cnnModel = Convolution2D(filters=256, kernel_size=3, activation='relu')(cnnModel)\n",
        "cnnModel = BatchNormalization()(cnnModel)\n",
        "cnnModel = MaxPooling2D(pool_size=2, strides=2)(cnnModel)\n",
        "\n",
        "cnnModel = Convolution2D(filters=512, kernel_size=3, activation='relu')(cnnModel)\n",
        "cnnModel = BatchNormalization()(cnnModel)\n",
        "cnnModel = MaxPooling2D(pool_size=2, strides=2)(cnnModel)\n",
        "\n",
        "cnnModel = Convolution2D(filters=1024, kernel_size=3, activation='relu')(cnnModel)\n",
        "cnnModel = BatchNormalization()(cnnModel)\n",
        "cnnModel = MaxPooling2D(pool_size=2, strides=2)(cnnModel)\n",
        "\n",
        "cnnModel = Dropout(0.5)(cnnModel)\n",
        "outputs = Flatten()(cnnModel)\n",
        "\n",
        "cnnModel = Model(inputs=inputs, outputs=outputs)\n",
        "cnnModel.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_9H1SE1cpIBz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "774009af-3737-40e5-c001-34c4e953c0e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min frame:  11\n",
            "Max frame:  63\n"
          ]
        }
      ],
      "source": [
        "# store dataset file path to a variable and find min and max frame size\n",
        "datasetFilePath = []\n",
        "maxFrame = 0\n",
        "minFrame = 500\n",
        "for index1, folderName in enumerate(os.listdir(\"10sentence/\")):\n",
        "    for index2, folderName2 in enumerate(os.listdir(\"10sentence/\" + folderName)):\n",
        "        framesLength = len(os.listdir(\"10sentence/\" + folderName + \"/\" + folderName2))\n",
        "        if(framesLength > maxFrame):\n",
        "          maxFrame = framesLength\n",
        "        if(framesLength < minFrame):\n",
        "          minFrame = framesLength\n",
        "        datasetFilePath.append([folderName, folderName2])\n",
        "print(\"Min frame: \", minFrame)\n",
        "print(\"Max frame: \", maxFrame)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "a2ZrH1xil7Ls",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "97e22548-eb5d-4234-c2d5-8035f7177f94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "video 206 :  do not worry\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=224x224 at 0x7F6FD5871650>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOAAAADgCAAAAAA/RjU9AAADyUlEQVR4nO2dW3ejMBCDhz37//+y96FNFhIgmIyksY++hzbpzRYaxhdsN8IYY4wxxhhjjDHGGGOMMYbHQi+xcQtmC2zskv9winnQdl8i+csp5geSpg1MB9vpWxBEgQr/6PfgBopipUAKPIE7fjEstINQCBZO7yCtq7Y1a3l8CV6+0kHKxaV21R4we/gKB5e3F0CmTzICgdwhKKu0Ri1tBdVBgT6qQIU+J5nhIQqURKgdHB6WQE18htJB0iSbTCBrEpE+XGq/0cqK2emTDN1BdraZ3kFhFuWkGVqIyhpCMziKyGnMYgVJRvMgFM9/XaT8SWZOVWumVzi7PhWiDgavpZh+RK9icnnGGGOMMROAHyQyF6VL+p/SJc0nX06DJlA1fGAJbM8P8RKsYOWcZxPt8E1ENOjYnuLgqT6wh4yZkXcBy8u3gLUgOHjBIKCHeIFnlW9Xfug70AKvtu4whWCBotZ9BVTgJ/sYzSFS4EmdeVvRgAJ7a4xRWGkHKGS4gRN4p7YAhbg+xL3Kpten2lKudA9hAqs8PqrmYPqFKScwGwukkxyj9QQmAxNYZX0ozsEiCoEhqlfYQrTNnESLhk0yNy1MS6NLhLPo+EAF6tNMSQdzL0s9gcm2YwX2V3bJDutiDubfteyGfomzhg6QldCJbv+QjiOJybWhnKn0ofwN2ZVp4TOdsPwoxM6/Fcii2COeCgjMb/uefzhqdBcjgrypcCYgV62SG6h7sMxmOoTAtvooBxFK9MPCz8A2EwUCtUI7CAW+0gn89z9iB7/lhoWprmtXGx78QqbCeiFa/wHo2wKmrl/OzkqMAe9OnQ96AICcKxrRtz2JkCYF0Jm6XM+Xstvxt75Autrww3aDFMSH+eM7OupmAr7uXv6MHj36lwsMcIdcHaJwLHB0LLAb+Rh+ix0cHQvspdgtWNXBvMtUVGAeFqhhjhE9BQvspcAjwQ12UIPbwcu4qzY6FigiLdKrCkwjW2C1HGMHhydbYFZXNK1LawdHxwJHxwJHxwJHxwJ7qTarhlpGwtg5dwlQiC6bT0ogAhfslsAu0ElGrtBZdHQssJtle9+pb0KAg2pJW/AhKtZbYUFsxPMy5Hd9iiSZ5eDz9xAEdlV2+iNw0xWWE5gNQ2CfKckHUNjB0aEI/Bhxy+nbr6jnYP0trjv0p5k0cCel33TCB4l3Auxsd/9HLMgkI8nBK1oxeyVhJwJFiWlf3j0oG/aWSDJI9TSBPSIyYxs6ZXExj64eZAw2ZXF7/jBRZ4l7EAlRoCaRFnBwJRzQcoIElmjjIyLiHzGOmkDHJNjCAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# segment, extract features and save features to CSV file for video frames\n",
        "for i1, folderName in enumerate(datasetFilePath):\n",
        "    sentence = []\n",
        "    for i, fileName in enumerate(os.listdir(\"10sentence/\" + folderName[0] + \"/\" + folderName[1])):\n",
        "        if fileName.endswith(\".jpg\"):\n",
        "          img = cv2.imread(\"10sentence/\" + folderName[0] + \"/\" + folderName[1] + \"/\" + fileName)\n",
        "          img = cv2.resize(img, (224, 224))\n",
        "\n",
        "          # skin detection \n",
        "          # https://github.com/CHEREF-Mehdi/SkinDetection/blob/master/SkinDetection.py\n",
        "\n",
        "          # converting from gbr to hsv color space\n",
        "          img_HSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "          # skin color range for hsv color space\n",
        "          HSV_mask = cv2.inRange(img_HSV, (0, 15, 0), (17, 170, 255))\n",
        "          HSV_mask = cv2.morphologyEx(HSV_mask, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8))\n",
        "\n",
        "          # converting from gbr to YCbCr color space\n",
        "          img_YCrCb = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
        "          # skin color range for hsv color space\n",
        "          YCrCb_mask = cv2.inRange(img_YCrCb, (0, 135, 85), (255, 180, 135))\n",
        "          YCrCb_mask = cv2.morphologyEx(YCrCb_mask, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8))\n",
        "\n",
        "          # merge skin detection (YCbCr and hsv)\n",
        "          global_mask = cv2.bitwise_and(YCrCb_mask, HSV_mask)\n",
        "          global_mask = cv2.medianBlur(global_mask, 3)\n",
        "          global_mask = cv2.morphologyEx(global_mask, cv2.MORPH_OPEN, np.ones((4, 4), np.uint8))\n",
        "\n",
        "          HSV_result = cv2.bitwise_not(HSV_mask)\n",
        "          YCrCb_result = cv2.bitwise_not(YCrCb_mask)\n",
        "          global_result = cv2.bitwise_not(global_mask)\n",
        "          \n",
        "          clear_output(wait=True)\n",
        "          print(\"video\",i1,\": \",folderName[0])\n",
        "          cv2_imshow(global_result)\n",
        "          cv2.waitKey(1)\n",
        "          \n",
        "          global_result = image.img_to_array(global_result)\n",
        "          global_result = np.expand_dims(global_result, axis=0)\n",
        "          r1 = cnnModel.predict(global_result)\n",
        "          sentence.append(r1[0])\n",
        "\n",
        "    # pad missing frames\n",
        "    for i in range(len(sentence), maxFrame):\n",
        "        paddingFeauters=[]\n",
        "        for j in range(0,len(sentence[0])):\n",
        "          arr1 = np.array([0])\n",
        "          arr2 = np.array(paddingFeauters)\n",
        "          paddingFeauters = np.concatenate((arr1, arr2))\n",
        "        sentence.append(paddingFeauters)\n",
        "\n",
        "    # prepare header for csv file\n",
        "    header=[]\n",
        "    for j in range(0,len(sentence[0])):\n",
        "        p = 'F-'+str(j)\n",
        "        arr1 = np.array([p])\n",
        "        arr2 = np.array(header)\n",
        "        header = np.concatenate((arr1, arr2))\n",
        "    header = header[::-1]\n",
        "\n",
        "    # save vedio featuers to csv file\n",
        "    for i in range(0, maxFrame):\n",
        "        a = np.array(sentence[i])\n",
        "        a = np.append(a, folderName[0])\n",
        "        if i1 == 0:\n",
        "          h = np.array(header)\n",
        "          h = np.append(h, \"class\")\n",
        "        with open('dataset_v1.csv', 'a+', newline='') as f:\n",
        "            write = csv.writer(f)\n",
        "            if i1 == 0 and i == 0:\n",
        "              write.writerow(h)\n",
        "            write.writerow(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "DJ2uZVlOFNCO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "425dd49a-adc6-44c5-b724-3611289575b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            F-0       F-1       F-2       F-3        F-4       F-5  F-6  \\\n",
            "0      4.307698  7.933354  0.002982  7.865017   9.594213  1.175911  0.0   \n",
            "1      3.624532  7.638630  0.358289  6.832114  11.712733  3.011297  0.0   \n",
            "2      4.909181  8.484513  0.000000  7.831418  11.029656  1.910458  0.0   \n",
            "3      4.381569  8.296061  0.000000  8.583636  10.520808  1.514985  0.0   \n",
            "4      5.181141  8.855169  0.504565  7.661772  10.921311  1.622769  0.0   \n",
            "...         ...       ...       ...       ...        ...       ...  ...   \n",
            "13036  0.000000  0.000000  0.000000  0.000000   0.000000  0.000000  0.0   \n",
            "13037  0.000000  0.000000  0.000000  0.000000   0.000000  0.000000  0.0   \n",
            "13038  0.000000  0.000000  0.000000  0.000000   0.000000  0.000000  0.0   \n",
            "13039  0.000000  0.000000  0.000000  0.000000   0.000000  0.000000  0.0   \n",
            "13040  0.000000  0.000000  0.000000  0.000000   0.000000  0.000000  0.0   \n",
            "\n",
            "            F-7       F-8  F-9  ...    F-1015    F-1016  F-1017    F-1018  \\\n",
            "0      0.481354  0.000000  0.0  ...  2.319379  5.239066     0.0  3.972274   \n",
            "1      1.904240  0.301867  0.0  ...  1.789184  4.410002     0.0  2.046296   \n",
            "2      1.747535  0.000000  0.0  ...  1.372988  3.249032     0.0  2.603509   \n",
            "3      1.747988  0.000000  0.0  ...  1.868996  5.262315     0.0  2.295254   \n",
            "4      1.803667  0.000000  0.0  ...  2.005636  4.485699     0.0  1.401460   \n",
            "...         ...       ...  ...  ...       ...       ...     ...       ...   \n",
            "13036  0.000000  0.000000  0.0  ...  0.000000  0.000000     0.0  0.000000   \n",
            "13037  0.000000  0.000000  0.0  ...  0.000000  0.000000     0.0  0.000000   \n",
            "13038  0.000000  0.000000  0.0  ...  0.000000  0.000000     0.0  0.000000   \n",
            "13039  0.000000  0.000000  0.0  ...  0.000000  0.000000     0.0  0.000000   \n",
            "13040  0.000000  0.000000  0.0  ...  0.000000  0.000000     0.0  0.000000   \n",
            "\n",
            "         F-1019    F-1020    F-1021    F-1022  F-1023               class  \n",
            "0      0.476297  0.228609  4.133882  1.042940     0.0  how can i help you  \n",
            "1      0.092967  0.000000  2.195485  0.434617     0.0  how can i help you  \n",
            "2      0.047888  0.883011  2.175866  0.969391     0.0  how can i help you  \n",
            "3      0.000000  0.271359  3.173037  0.646145     0.0  how can i help you  \n",
            "4      0.999569  0.000000  2.675583  0.661731     0.0  how can i help you  \n",
            "...         ...       ...       ...       ...     ...                 ...  \n",
            "13036  0.000000  0.000000  0.000000  0.000000     0.0        do not worry  \n",
            "13037  0.000000  0.000000  0.000000  0.000000     0.0        do not worry  \n",
            "13038  0.000000  0.000000  0.000000  0.000000     0.0        do not worry  \n",
            "13039  0.000000  0.000000  0.000000  0.000000     0.0        do not worry  \n",
            "13040  0.000000  0.000000  0.000000  0.000000     0.0        do not worry  \n",
            "\n",
            "[13041 rows x 1025 columns]\n"
          ]
        }
      ],
      "source": [
        "dataset_train = pd.read_csv('dataset_v1.csv')\n",
        "print(dataset_train)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Feature_extraction_and_dataset_preparation.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}